{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8c3bfd",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a509df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing\n",
    "from gensim.utils import simple_preprocess\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b5dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (C:/Users/psdda/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c32f2dd6f1043f186fee5911f185e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1658014</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adrienne%20Mayor</td>\n",
       "      <td>Adrienne Mayor</td>\n",
       "      <td>Adrienne Mayor (born 1946) is a historian of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415109</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jo%20Stafford</td>\n",
       "      <td>Jo Stafford</td>\n",
       "      <td>Jo Elizabeth Stafford (November 12, 1917July 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>733308</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Milan%20Rapai%C4%87</td>\n",
       "      <td>Milan Rapaić</td>\n",
       "      <td>Milan \"Miki\" Rapaić (born 16 August 1973) is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2597099</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Windsor%20North%...</td>\n",
       "      <td>Windsor North School</td>\n",
       "      <td>Windsor North School is a primary school in In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>690250</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List%20of%20rive...</td>\n",
       "      <td>List of rivers of Missouri</td>\n",
       "      <td>List of rivers in Missouri (U.S. state).\\n\\nBy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>670737</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Standesamt%20Ade...</td>\n",
       "      <td>Standesamt Adelnau</td>\n",
       "      <td>Standesamt Adelnau was one of the civil regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>580501</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Siaka%20Stevens</td>\n",
       "      <td>Siaka Stevens</td>\n",
       "      <td>Siaka Probyn Stevens (24 August 1905 – 29 May ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2214203</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Malitbog</td>\n",
       "      <td>Malitbog</td>\n",
       "      <td>Malitbog is the name of several places in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2177759</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Calyx%20%28music...</td>\n",
       "      <td>Calyx (musician)</td>\n",
       "      <td>Calyx is a British drum and bass act, speciali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2350397</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ametsuchi%20no%2...</td>\n",
       "      <td>Ametsuchi no Uta</td>\n",
       "      <td>The  or  is a Japanese pangram, authored in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                                url  \\\n",
       "0      1658014     https://en.wikipedia.org/wiki/Adrienne%20Mayor   \n",
       "1       415109        https://en.wikipedia.org/wiki/Jo%20Stafford   \n",
       "2       733308  https://en.wikipedia.org/wiki/Milan%20Rapai%C4%87   \n",
       "3      2597099  https://en.wikipedia.org/wiki/Windsor%20North%...   \n",
       "4       690250  https://en.wikipedia.org/wiki/List%20of%20rive...   \n",
       "...        ...                                                ...   \n",
       "99995   670737  https://en.wikipedia.org/wiki/Standesamt%20Ade...   \n",
       "99996   580501      https://en.wikipedia.org/wiki/Siaka%20Stevens   \n",
       "99997  2214203             https://en.wikipedia.org/wiki/Malitbog   \n",
       "99998  2177759  https://en.wikipedia.org/wiki/Calyx%20%28music...   \n",
       "99999  2350397  https://en.wikipedia.org/wiki/Ametsuchi%20no%2...   \n",
       "\n",
       "                            title  \\\n",
       "0                  Adrienne Mayor   \n",
       "1                     Jo Stafford   \n",
       "2                    Milan Rapaić   \n",
       "3            Windsor North School   \n",
       "4      List of rivers of Missouri   \n",
       "...                           ...   \n",
       "99995          Standesamt Adelnau   \n",
       "99996               Siaka Stevens   \n",
       "99997                    Malitbog   \n",
       "99998            Calyx (musician)   \n",
       "99999            Ametsuchi no Uta   \n",
       "\n",
       "                                                    text  \n",
       "0      Adrienne Mayor (born 1946) is a historian of a...  \n",
       "1      Jo Elizabeth Stafford (November 12, 1917July 1...  \n",
       "2      Milan \"Miki\" Rapaić (born 16 August 1973) is a...  \n",
       "3      Windsor North School is a primary school in In...  \n",
       "4      List of rivers in Missouri (U.S. state).\\n\\nBy...  \n",
       "...                                                  ...  \n",
       "99995  Standesamt Adelnau was one of the civil regist...  \n",
       "99996  Siaka Probyn Stevens (24 August 1905 – 29 May ...  \n",
       "99997  Malitbog is the name of several places in the ...  \n",
       "99998  Calyx is a British drum and bass act, speciali...  \n",
       "99999  The  or  is a Japanese pangram, authored in th...  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "wikidata = datasets.load_dataset(\"wikipedia\", \"20220301.en\", split=['train[:10%]'])\n",
    "df_wiki = wikidata[0].to_pandas().sample(frac=1, random_state=42).reset_index(drop=True)[:100000]\n",
    "df_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208552d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  fucntion to clean text\n",
    "def text_cleaner(text):\n",
    "    clean_text = text.lower() # change to lower case\n",
    "    url = r'''(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'''\n",
    "    clean_text = re.sub(url, '', clean_text) # remove url links\n",
    "    clean_text = re.sub(r'\\([^)]*\\)', '', clean_text) # remove text inside ()\n",
    "    clean_text = re.sub(r'\\[|\\]', '', clean_text) # remove []\n",
    "    clean_text = re.sub(r'\\“|\\”','', clean_text) # remove \"\"\n",
    "    clean_text = re.sub(r'\\\"','', clean_text) # remove \"\n",
    "    clean_text = re.sub(r\"(?<=\\d),(?=\\d)\", \"\", clean_text) # remove , inside digit\n",
    "    clean_text = re.sub(r\"[\\-\\—]\", \" \", clean_text) # remove - and -- \n",
    "    clean_text = re.sub(r\"\\d+\", \"number\", clean_text) # replace digit to number token\n",
    "    clean_text = re.sub(r\"'s\", \"\", clean_text) # remove 's\n",
    "    clean_text = re.sub(r\"[^a-zA-Z0-9 \\,\\.\\!\\?]\", \"\", clean_text) # remove text that are not english characters\n",
    "    clean_text = re.sub(r\"\\s+\", \" \", clean_text) # remove extra white space\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd796c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusGenerator:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Python generator to feed data.\"\"\"\n",
    "        for i in range(len(self.data)):\n",
    "            document = self.data[\"text\"][i] # get text content\n",
    "            document_clean = text_cleaner(document) # clean text\n",
    "            words = simple_preprocess(document_clean) # split sentence to words\n",
    "            yield TaggedDocument(words=words, tags=[i]) # tag document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264acbd8",
   "metadata": {},
   "source": [
    "## Train Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4114958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Doc2Vec model\n",
    "model = Doc2Vec(vector_size=32, window=10, min_count=2, sample=1e-4, negative=5, workers=multiprocessing.cpu_count(), dm=1)\n",
    "wiki_corpus = CorpusGenerator(df_wiki)\n",
    "model.build_vocab(wiki_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c4914ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.train(wiki_corpus, total_examples=model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6f6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./doc2vec_model/doc2vecmodel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe03595",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = Doc2Vec.load('./doc2vec_model/doc2vecmodel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a83f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_documents(text, top_n):\n",
    "    \"\"\"Find similar documents with the input document.\"\"\"\n",
    "    doc_vector = load_model.infer_vector(text)\n",
    "    sims = load_model.dv.most_similar([doc_vector], topn=top_n)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5091c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trie class\n",
    "# reference: https://www.geeksforgeeks.org/auto-complete-feature-using-trie/\n",
    "class TrieNode():\n",
    "    def __init__(self):\n",
    "        # Initialising one node for trie\n",
    "        self.children = {}\n",
    "        self.last = False\n",
    " \n",
    " \n",
    "class Trie():\n",
    "    def __init__(self):\n",
    " \n",
    "        # Initialising the trie structure.\n",
    "        self.root = TrieNode()\n",
    " \n",
    "    def formTrie(self, keys):\n",
    " \n",
    "        # Forms a trie structure with the given set of strings\n",
    "        # if it does not exists already else it merges the key\n",
    "        # into it by extending the structure as required\n",
    "        for key in keys:\n",
    "            self.insert(key)  # inserting one key to the trie.\n",
    " \n",
    "    def insert(self, key):\n",
    " \n",
    "        # Inserts a key into trie if it does not exist already.\n",
    "        # And if the key is a prefix of the trie node, just\n",
    "        # marks it as leaf node.\n",
    "        node = self.root\n",
    " \n",
    "        for a in key:\n",
    "            if not node.children.get(a):\n",
    "                node.children[a] = TrieNode()\n",
    " \n",
    "            node = node.children[a]\n",
    " \n",
    "        node.last = True\n",
    " \n",
    "    def suggestionsRec(self, node, word):\n",
    " \n",
    "        # Method to recursively traverse the trie\n",
    "        # and return a whole word.\n",
    "        if node.last:\n",
    "            print(word)\n",
    " \n",
    "        for a, n in node.children.items():\n",
    "            self.suggestionsRec(n, word + a)\n",
    " \n",
    "    def printAutoSuggestions(self, key):\n",
    " \n",
    "        # Returns all the words in the trie whose common\n",
    "        # prefix is the given key thus listing out all\n",
    "        # the suggestions for autocomplete.\n",
    "        node = self.root\n",
    " \n",
    "        for a in key:\n",
    "            # no string in the Trie has this prefix\n",
    "            if not node.children.get(a):\n",
    "                return 0\n",
    "            node = node.children[a]\n",
    " \n",
    "        # If prefix is present as a word, but\n",
    "        # there is no subtree below the last\n",
    "        # matching node.\n",
    "        if not node.children:\n",
    "            return -1\n",
    " \n",
    "        self.suggestionsRec(node, key)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fc18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(text, document_size=100):\n",
    "    text_word = text.split()\n",
    "    last_word = text_word.pop() # get prefix\n",
    "    similar_index = find_similar_documents(text_word, document_size) # find top similar documents\n",
    "    # create a list of words\n",
    "    keys = []\n",
    "    for pair in similar_index:\n",
    "        index = pair[0]\n",
    "        keys.extend(simple_preprocess(df_wiki[\"text\"][index]))\n",
    "        \n",
    "    # creating trie object\n",
    "    t = Trie()\n",
    " \n",
    "    # creating the trie structure with the\n",
    "    # given set of strings.\n",
    "    t.formTrie(keys)\n",
    "    # make suggestion based on prefix\n",
    "    comp = t.printAutoSuggestions(last_word)\n",
    "    \n",
    "    if comp == -1:\n",
    "        print(f\"No other words found with prefix {last_word}\")\n",
    "    elif comp == 0:\n",
    "        print(f\"No words found with prefix {last_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913164ed",
   "metadata": {},
   "source": [
    "## Test autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80cb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movement\n",
      "movements\n",
      "moving\n"
     ]
    }
   ],
   "source": [
    "autocomplete(\"Anarchism is a political philosophy and mov\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a332468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal\n",
      "caleb\n",
      "california\n",
      "caliph\n",
      "caliphate\n",
      "call\n",
      "called\n",
      "calleja\n",
      "calling\n",
      "caldera\n",
      "calderón\n",
      "calhoun\n"
     ]
    }
   ],
   "source": [
    "autocomplete(\"April is the fourth month of the year in the Julian and Gregorian cal\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74258842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute\n",
      "computer\n",
      "computers\n",
      "computerworld\n",
      "computerized\n",
      "computed\n",
      "computes\n",
      "computation\n",
      "computational\n",
      "computationally\n",
      "computations\n",
      "computability\n",
      "computable\n",
      "computing\n",
      "compuflo\n"
     ]
    }
   ],
   "source": [
    "autocomplete(\"Natural language processing is a subfield of linguistics, compu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
