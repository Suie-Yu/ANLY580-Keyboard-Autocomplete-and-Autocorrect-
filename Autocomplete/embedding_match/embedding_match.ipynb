{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13133c80",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d23da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (C:/Users/psdda/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e4db2f44d848c4914ae6f44713fe77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1658014</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adrienne%20Mayor</td>\n",
       "      <td>Adrienne Mayor</td>\n",
       "      <td>Adrienne Mayor (born 1946) is a historian of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415109</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jo%20Stafford</td>\n",
       "      <td>Jo Stafford</td>\n",
       "      <td>Jo Elizabeth Stafford (November 12, 1917July 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>733308</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Milan%20Rapai%C4%87</td>\n",
       "      <td>Milan Rapaić</td>\n",
       "      <td>Milan \"Miki\" Rapaić (born 16 August 1973) is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2597099</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Windsor%20North%...</td>\n",
       "      <td>Windsor North School</td>\n",
       "      <td>Windsor North School is a primary school in In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>690250</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List%20of%20rive...</td>\n",
       "      <td>List of rivers of Missouri</td>\n",
       "      <td>List of rivers in Missouri (U.S. state).\\n\\nBy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                url  \\\n",
       "0  1658014     https://en.wikipedia.org/wiki/Adrienne%20Mayor   \n",
       "1   415109        https://en.wikipedia.org/wiki/Jo%20Stafford   \n",
       "2   733308  https://en.wikipedia.org/wiki/Milan%20Rapai%C4%87   \n",
       "3  2597099  https://en.wikipedia.org/wiki/Windsor%20North%...   \n",
       "4   690250  https://en.wikipedia.org/wiki/List%20of%20rive...   \n",
       "\n",
       "                        title  \\\n",
       "0              Adrienne Mayor   \n",
       "1                 Jo Stafford   \n",
       "2                Milan Rapaić   \n",
       "3        Windsor North School   \n",
       "4  List of rivers of Missouri   \n",
       "\n",
       "                                                text  \n",
       "0  Adrienne Mayor (born 1946) is a historian of a...  \n",
       "1  Jo Elizabeth Stafford (November 12, 1917July 1...  \n",
       "2  Milan \"Miki\" Rapaić (born 16 August 1973) is a...  \n",
       "3  Windsor North School is a primary school in In...  \n",
       "4  List of rivers in Missouri (U.S. state).\\n\\nBy...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "wikidata = datasets.load_dataset(\"wikipedia\", \"20220301.en\", split=['train[:10%]'])\n",
    "df_wiki = wikidata[0].to_pandas().sample(frac=1, random_state=42).reset_index(drop=True)[:100000]\n",
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd1daab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1658014</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adrienne%20Mayor</td>\n",
       "      <td>Adrienne Mayor</td>\n",
       "      <td>adrienne mayor is a historian of ancient scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415109</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jo%20Stafford</td>\n",
       "      <td>Jo Stafford</td>\n",
       "      <td>jo elizabeth stafford was an american traditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>733308</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Milan%20Rapai%C4%87</td>\n",
       "      <td>Milan Rapaić</td>\n",
       "      <td>milan miki rapai is a croatian former professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2597099</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Windsor%20North%...</td>\n",
       "      <td>Windsor North School</td>\n",
       "      <td>windsor north school is a primary school in in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>690250</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List%20of%20rive...</td>\n",
       "      <td>List of rivers of Missouri</td>\n",
       "      <td>list of rivers in missouri .by drainage basint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>670737</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Standesamt%20Ade...</td>\n",
       "      <td>Standesamt Adelnau</td>\n",
       "      <td>standesamt adelnau was one of the civil regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>580501</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Siaka%20Stevens</td>\n",
       "      <td>Siaka Stevens</td>\n",
       "      <td>siaka probyn stevens was the leader of sierra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2214203</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Malitbog</td>\n",
       "      <td>Malitbog</td>\n",
       "      <td>malitbog is the name of several places in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2177759</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Calyx%20%28music...</td>\n",
       "      <td>Calyx (musician)</td>\n",
       "      <td>calyx is a british drum and bass act, speciali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2350397</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ametsuchi%20no%2...</td>\n",
       "      <td>Ametsuchi no Uta</td>\n",
       "      <td>the or is a japanese pangram, authored in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                                url  \\\n",
       "0      1658014     https://en.wikipedia.org/wiki/Adrienne%20Mayor   \n",
       "1       415109        https://en.wikipedia.org/wiki/Jo%20Stafford   \n",
       "2       733308  https://en.wikipedia.org/wiki/Milan%20Rapai%C4%87   \n",
       "3      2597099  https://en.wikipedia.org/wiki/Windsor%20North%...   \n",
       "4       690250  https://en.wikipedia.org/wiki/List%20of%20rive...   \n",
       "...        ...                                                ...   \n",
       "99995   670737  https://en.wikipedia.org/wiki/Standesamt%20Ade...   \n",
       "99996   580501      https://en.wikipedia.org/wiki/Siaka%20Stevens   \n",
       "99997  2214203             https://en.wikipedia.org/wiki/Malitbog   \n",
       "99998  2177759  https://en.wikipedia.org/wiki/Calyx%20%28music...   \n",
       "99999  2350397  https://en.wikipedia.org/wiki/Ametsuchi%20no%2...   \n",
       "\n",
       "                            title  \\\n",
       "0                  Adrienne Mayor   \n",
       "1                     Jo Stafford   \n",
       "2                    Milan Rapaić   \n",
       "3            Windsor North School   \n",
       "4      List of rivers of Missouri   \n",
       "...                           ...   \n",
       "99995          Standesamt Adelnau   \n",
       "99996               Siaka Stevens   \n",
       "99997                    Malitbog   \n",
       "99998            Calyx (musician)   \n",
       "99999            Ametsuchi no Uta   \n",
       "\n",
       "                                                    text  \n",
       "0      adrienne mayor is a historian of ancient scien...  \n",
       "1      jo elizabeth stafford was an american traditio...  \n",
       "2      milan miki rapai is a croatian former professi...  \n",
       "3      windsor north school is a primary school in in...  \n",
       "4      list of rivers in missouri .by drainage basint...  \n",
       "...                                                  ...  \n",
       "99995  standesamt adelnau was one of the civil regist...  \n",
       "99996  siaka probyn stevens was the leader of sierra ...  \n",
       "99997  malitbog is the name of several places in the ...  \n",
       "99998  calyx is a british drum and bass act, speciali...  \n",
       "99999  the or is a japanese pangram, authored in the ...  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    clean_text = text.lower() # change to lower case\n",
    "    # regex to match most of url links\n",
    "    url = r'''(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}\n",
    "    |www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}\n",
    "    |www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'''\n",
    "    clean_text = re.sub(url, '', clean_text) # remove url links\n",
    "    clean_text = re.sub(r'\\([^)]*\\)', '', clean_text) # remove text inside ()\n",
    "    clean_text = re.sub(r'\\[|\\]', '', clean_text) # remove []\n",
    "    clean_text = re.sub(r'\\“|\\”','', clean_text) # remove \"\"\n",
    "    clean_text = re.sub(r'\\\"','', clean_text) # remove \"\n",
    "    clean_text = re.sub(r\"(?<=\\d),(?=\\d)\", \"\", clean_text) # remove , inside digit\n",
    "    clean_text = re.sub(r\"[\\-\\—]\", \" \", clean_text) # remove - and -- \n",
    "    clean_text = re.sub(r\"\\d+\", \"number\", clean_text) # replace digit to number token\n",
    "    clean_text = re.sub(r\"'s\", \"\", clean_text) # remove 's\n",
    "    clean_text = re.sub(r\"[^a-zA-Z0-9 \\,\\.\\!\\?]\", \"\", clean_text) # remove text that are not english characters\n",
    "    clean_text = re.sub(r\"\\s+\", \" \", clean_text) # remove extra white space\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "df_wiki[\"text\"] = df_wiki[\"text\"].apply(lambda x: text_cleaner(x))\n",
    "df_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98363af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adrienne mayor is a historian of ancient scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mayor specializes in ancient history and the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her work in pre scientific fossil discoveries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mayor book, greek fire, poison arrows, the sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lifefrom number to number, she worked as a cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>external linksa mills revival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>by s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aronowitzcontemporary analysis of c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wright millson intellectual craftsmanship fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todaynumberhttpssociological imagination in li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176896 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence\n",
       "0   adrienne mayor is a historian of ancient scien...\n",
       "0   mayor specializes in ancient history and the s...\n",
       "0    her work in pre scientific fossil discoveries...\n",
       "0    mayor book, greek fire, poison arrows, the sc...\n",
       "0   lifefrom number to number, she worked as a cop...\n",
       "..                                                ...\n",
       "0                       external linksa mills revival\n",
       "0                                                by s\n",
       "0                 aronowitzcontemporary analysis of c\n",
       "0    wright millson intellectual craftsmanship fro...\n",
       "0   todaynumberhttpssociological imagination in li...\n",
       "\n",
       "[1176896 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split documents into sentences\n",
    "sentence_pharser = \"\\. |\\? |\\! \"\n",
    "df_sentence = pd.concat([pd.DataFrame({'sentence': doc}, index=[0])\n",
    "           for _, row in df_wiki.loc[:20000].iterrows()\n",
    "           for doc in re.split(\"\\.|\\?|\\! \", row[\"text\"]) if doc != ''])\n",
    "df_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583c00a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adrienne mayor is a historian of ancient scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mayor specializes in ancient history and the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>her work in pre scientific fossil discoveries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mayor book, greek fire, poison arrows, the sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lifefrom number to number, she worked as a cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>external linksa mills revival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>by s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aronowitzcontemporary analysis of c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wright millson intellectual craftsmanship from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>todaynumberhttpssociological imagination in li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176896 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence\n",
       "0   adrienne mayor is a historian of ancient scien...\n",
       "0   mayor specializes in ancient history and the s...\n",
       "0   her work in pre scientific fossil discoveries ...\n",
       "0   mayor book, greek fire, poison arrows, the sco...\n",
       "0   lifefrom number to number, she worked as a cop...\n",
       "..                                                ...\n",
       "0                       external linksa mills revival\n",
       "0                                                by s\n",
       "0                 aronowitzcontemporary analysis of c\n",
       "0   wright millson intellectual craftsmanship from...\n",
       "0   todaynumberhttpssociological imagination in li...\n",
       "\n",
       "[1176896 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove trailing and ending whitespaces\n",
    "df_sentence[\"sentence\"] = df_sentence[\"sentence\"].apply(lambda x: x.strip())\n",
    "df_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cca6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adrienne mayor is a historian of ancient scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mayor specializes in ancient history and the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>her work in pre scientific fossil discoveries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mayor book, greek fire, poison arrows, the sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lifefrom number to number, she worked as a cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176891</th>\n",
       "      <td>external linksa mills revival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176892</th>\n",
       "      <td>by s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176893</th>\n",
       "      <td>aronowitzcontemporary analysis of c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176894</th>\n",
       "      <td>wright millson intellectual craftsmanship from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176895</th>\n",
       "      <td>todaynumberhttpssociological imagination in li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176896 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence\n",
       "0        adrienne mayor is a historian of ancient scien...\n",
       "1        mayor specializes in ancient history and the s...\n",
       "2        her work in pre scientific fossil discoveries ...\n",
       "3        mayor book, greek fire, poison arrows, the sco...\n",
       "4        lifefrom number to number, she worked as a cop...\n",
       "...                                                    ...\n",
       "1176891                      external linksa mills revival\n",
       "1176892                                               by s\n",
       "1176893                aronowitzcontemporary analysis of c\n",
       "1176894  wright millson intellectual craftsmanship from...\n",
       "1176895  todaynumberhttpssociological imagination in li...\n",
       "\n",
       "[1176896 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence = df_sentence.dropna() # drop missing sentence\n",
    "df_sentence.index = [i for i in range(0, len(df_sentence))] # create index\n",
    "#df_sentence.to_csv(\"wiki_sentence.csv\", index=False) # save data\n",
    "df_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84740c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in dataframe\n",
    "df_sentence.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf720fe",
   "metadata": {},
   "source": [
    "## Build autocomplete system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a9b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AutocompleteByEmbedding:\n",
    "\n",
    "    def __init__(self, data, column, tokenizer, model):\n",
    "        self.data = data\n",
    "        self.col = column\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "  \n",
    "    def match_prefix(self, sentence, prefix):\n",
    "        \"\"\"Match prefix in sentence.\"\"\"\n",
    "        matcher = r\"\\b\" + prefix\n",
    "        prefix_match = re.search(matcher, sentence)\n",
    "        if prefix_match:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "  \n",
    "    def word_with_prefix(self, encoded, prefix):\n",
    "        \"\"\"Find all words containing prefix from Bert tokens.\"\"\"\n",
    "        words = []\n",
    "        for token in encoded['input_ids'][0]:\n",
    "            words.append(self.tokenizer.decode([token]))\n",
    "        index = []   \n",
    "        for i in range(len(words)):\n",
    "            if re.match(r'^' + prefix, words[i]):\n",
    "                index.append(i)\n",
    "        return index\n",
    "\n",
    "    def autocomplete(self, sentence, document_size=200, top_n=5, similarity=True):\n",
    "        words = sentence.split()\n",
    "        prefix = words[-1] # prefix is the last word in sentence\n",
    "        # filter all sentences containing prefix\n",
    "        sentence_with_prefix = self.data[self.col].apply(lambda x: self.match_prefix(x, prefix))\n",
    "        df_prefix = self.data[sentence_with_prefix]\n",
    "        # tokenize input sentence\n",
    "        encoded_input = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        output = self.model(**encoded_input)\n",
    "        # input sentence word embedding\n",
    "        input_embedding = output.last_hidden_state[-1].detach().numpy()\n",
    "        word_similarity = {}\n",
    "        # tokenize training sentence\n",
    "        for document in tqdm(df_prefix[self.col][:document_size]):\n",
    "            # tokenize training sentence\n",
    "            encoded_document = self.tokenizer(document, max_length=128, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            document_output = self.model(**encoded_document)\n",
    "            # training sentence word embedding\n",
    "            Y = document_output.last_hidden_state[-1].detach().numpy()\n",
    "            # find indices of words containign prefix in tokens\n",
    "            encoded_index = self.word_with_prefix(encoded_document, prefix)\n",
    "            # compute cosine similarity between input sentence and training sentence\n",
    "            cos_distance = cosine_similarity(input_embedding, Y)\n",
    "            for index in encoded_index:\n",
    "                # decode tokens to get real word\n",
    "                word = self.tokenizer.decode([encoded_document[\"input_ids\"][0][index]])\n",
    "                # get similarity between word and prefix\n",
    "                distance = cos_distance[len(input_embedding)-1-1, index]\n",
    "                # add word to result\n",
    "                if word not in word_similarity:\n",
    "                    word_similarity[word] = distance\n",
    "                elif word_similarity[word] < distance:\n",
    "                    word_similarity[word] = distance\n",
    "                else:\n",
    "                    continue\n",
    "        # sort by word consine similarity\n",
    "        top_words = sorted(word_similarity, key=lambda x: -word_similarity[x])[:top_n]\n",
    "        result = []\n",
    "        for word in top_words:\n",
    "            result.append((word, word_similarity[word]))\n",
    "        # if result has length 0\n",
    "        # use words in training sentences as result\n",
    "        if len(result) == 0:\n",
    "            size = min(document_size, len(df_prefix))\n",
    "            train_words = {}\n",
    "            # count occurrence for words containg prefix\n",
    "            for document in df_prefix[\"sentence\"][:size]:\n",
    "                pattern = r\"\\b\" + prefix + \"[a-z]*\"\n",
    "                search = re.search(pattern, document)\n",
    "                train_words[search[0]] = train_words.get(search[0], 0) + 1\n",
    "            sorted_words = sorted(train_words, key=lambda x: -train_words[x])[:top_n]\n",
    "            # use word frequency as probability\n",
    "            for word in sorted_words:\n",
    "                result.append((word, train_words[word] / size))\n",
    "        if len(result) == 0:\n",
    "            print(\"Cannot complete word \" + prefix)\n",
    "        if similarity:\n",
    "            return result\n",
    "        else:\n",
    "            predicted_words = []\n",
    "            predicted_words = [pair[0] for pair in result]\n",
    "            return predicted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0516cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "bert_autocomplete = AutocompleteByEmbedding(data=df_sentence, column=\"sentence\", tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab1819",
   "metadata": {},
   "source": [
    "## Test autocomplete feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c33e803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:41<00:00,  4.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('strangely', 0.5754252),\n",
       " ('strong', 0.52829254),\n",
       " ('street', 0.5196318),\n",
       " ('strategy', 0.4686629),\n",
       " ('structure', 0.44376096)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"That which does not kill us make us str\"\n",
    "bert_autocomplete.autocomplete(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a384181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:42<00:00,  4.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('science', 0.6582532),\n",
       " ('sciences', 0.62737536),\n",
       " ('scientist', 0.53728306),\n",
       " ('scissors', 0.5202313),\n",
       " ('scientists', 0.512413)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Natural language processing is a subfield of linguistics, computer sci\"\n",
    "bert_autocomplete.autocomplete(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511aaa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:39<00:00,  5.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('technology', 0.5973148),\n",
       " ('thought', 0.51470196),\n",
       " ('tactics', 0.5123917),\n",
       " ('terminology', 0.45969445),\n",
       " ('together', 0.45541796)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_autocomplete.autocomplete(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b5c2405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:40<00:00,  4.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pre', 0.4764853),\n",
       " ('peers', 0.46667928),\n",
       " ('points', 0.46472567),\n",
       " ('performance', 0.46284923),\n",
       " ('philology', 0.45699662)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_autocomplete.autocomplete(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27314960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('vrindavan', 0.4),\n",
       " ('vrindavana', 0.3),\n",
       " ('vrindavanam', 0.1),\n",
       " ('vrindabanin', 0.1),\n",
       " ('vrindaban', 0.1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct word: vrindavana\n",
    "text = \"kameshvara temple, in kamyavan, one of the twelve forests of vrind\"\n",
    "bert_autocomplete.autocomplete(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb9a047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:18<00:00,  4.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('subjugated', 0.4090909090909091),\n",
       " ('subjugation', 0.23863636363636365),\n",
       " ('subjugate', 0.1590909090909091),\n",
       " ('subjunctive', 0.09090909090909091),\n",
       " ('subjugating', 0.056818181818181816)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct word: subjunctive\n",
    "text = \"some important ones are declarative, affirmative, negative, emphatic, conditional, imperative, interrogative and subju\"\n",
    "bert_autocomplete.autocomplete(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61000d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:38<00:00,  5.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('references', 0.5986206),\n",
       " ('refurbished', 0.5270731),\n",
       " ('reflections', 0.5153293),\n",
       " ('ref', 0.5110934),\n",
       " ('reference', 0.51016015)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i have attached the file for your ref\"\n",
    "bert_autocomplete.autocomplete(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f625d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:38<00:00,  5.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('c', 0.8225794),\n",
       " ('company', 0.522678),\n",
       " ('club', 0.52197415),\n",
       " ('claims', 0.5059437),\n",
       " ('china', 0.50570166)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"jumping fox chasing c\"\n",
    "bert_autocomplete.autocomplete(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
